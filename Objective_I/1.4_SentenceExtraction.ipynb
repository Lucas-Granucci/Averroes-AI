{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc3c89fe",
   "metadata": {},
   "source": [
    "# Sentence Extraction\n",
    "\n",
    "This notebook extracts sentences from markdown documents using spaCy. It cleans and validates sentences, performs language verification, and saves valid sentences in JSONL format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e5a885",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import re\n",
    "import json\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from lingua import LanguageDetectorBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d307482",
   "metadata": {},
   "source": [
    "### Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a10eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open(\"../config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set up project paths\n",
    "project_root = Path.cwd().parent\n",
    "SENTENCES_DIR = project_root / config[\"SENTENCES_DIR\"]\n",
    "EXTRACTED_DIR = project_root / config[\"EXTRACTED_DIR\"]\n",
    "\n",
    "# Progress bar format\n",
    "PROGRESS_BAR_FORMAT = \"{desc:<25}{percentage:3.0f}%|{bar:20}{r_bar}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab587796",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text: str, detector):\n",
    "    \"\"\"Detect the language of the given text\"\"\"\n",
    "    result = detector.detect_language_of(text)\n",
    "    return result.iso_code_639_1.name.lower() if result else None\n",
    "\n",
    "\n",
    "def clean_sentence(sentence: str):\n",
    "    \"\"\"Clean markdown formatting from sentence\"\"\"\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence)\n",
    "    sentence = re.sub(r\"#+\\s*\", \"\", sentence)\n",
    "    sentence = re.sub(r\"\\*+\", \"\", sentence)\n",
    "    sentence = re.sub(r\"\\[|\\]|\\(|\\)\", \"\", sentence)\n",
    "    return sentence.strip()\n",
    "\n",
    "\n",
    "def is_valid_sentence(sentence: str, min_length: int = 10, max_length: int = 500):\n",
    "    \"\"\"Check if sentence meets validity criteria\"\"\"\n",
    "    if len(sentence) < min_length:\n",
    "        return False\n",
    "    if len(sentence) > max_length:\n",
    "        return False\n",
    "    if not re.search(r\"[a-zA-Z\\u0080-\\uFFFF]\", sentence):\n",
    "        return False\n",
    "    if len(re.findall(r\"[a-zA-Z\\u0080-\\uFFFF]\", sentence)) < 5:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1fcb1",
   "metadata": {},
   "source": [
    "## Extract Sentences\n",
    "\n",
    "Extract and validate sentences from markdown documents for all languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf276d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Tamil         100%|████████████████████| 84/84 [00:19<00:00,  4.36it/s]\n",
      "Extracting Bengali       100%|████████████████████| 27/27 [00:11<00:00,  2.43it/s]\n",
      "Extracting Thai          100%|████████████████████| 291/291 [02:49<00:00,  1.72it/s]\n",
      "Extracting Swahili       100%|████████████████████| 310/310 [04:26<00:00,  1.16it/s]\n",
      "Extracting Estonian      100%|████████████████████| 251/251 [04:28<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "extraction_stats = []\n",
    "nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "detector = LanguageDetectorBuilder.from_all_languages().build()\n",
    "\n",
    "for lang_code, lang_config in config[\"LANGUAGES\"].items():\n",
    "    lang_sents_file = SENTENCES_DIR / f\"{lang_code}_sentences.jsonl\"\n",
    "    lang_extracted_dir = EXTRACTED_DIR / lang_code\n",
    "\n",
    "    if not lang_extracted_dir.exists():\n",
    "        continue\n",
    "\n",
    "    markdown_files = list(lang_extracted_dir.glob(\"*.md\"))\n",
    "    total_sentences = 0\n",
    "\n",
    "    with open(lang_sents_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        for markdown_path in tqdm(\n",
    "            markdown_files,\n",
    "            total=len(markdown_files),\n",
    "            desc=f\"Extracting {lang_config['name']}\",\n",
    "            bar_format=PROGRESS_BAR_FORMAT\n",
    "        ):\n",
    "            try:\n",
    "                md_text = markdown_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "                # Clean markdown text\n",
    "                md_text = re.sub(r\"```.*?```\", \"\", md_text, flags=re.DOTALL)\n",
    "                md_text = re.sub(r\"\\|.*?\\|\", \"\", md_text)\n",
    "                md_text = re.sub(\n",
    "                    r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "                    \"\",\n",
    "                    md_text,\n",
    "                )\n",
    "\n",
    "                # Extract sentences\n",
    "                doc = nlp(md_text)\n",
    "\n",
    "                sentences = []\n",
    "                for sent in doc.sents:\n",
    "                    cleaned = clean_sentence(sent.text)\n",
    "                    detected_code = detect_language(cleaned, detector)\n",
    "                    if is_valid_sentence(cleaned) and detected_code == lang_code:\n",
    "                        sentences.append(cleaned)\n",
    "\n",
    "                # Save valid sentences\n",
    "                for idx, sentence in enumerate(sentences):\n",
    "                    data = {\n",
    "                        \"text\": sentence,\n",
    "                        \"lang\": lang_code,\n",
    "                        \"doc_id\": markdown_path.stem,\n",
    "                        \"sent_id\": idx,\n",
    "                    }\n",
    "                    out_file.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "                    total_sentences += 1\n",
    "\n",
    "                    if total_sentences >= lang_config[\"target_sentences\"]:\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error when extracting sentences: {str(e)}\")\n",
    "\n",
    "            if total_sentences >= lang_config[\"target_sentences\"]:\n",
    "                break\n",
    "\n",
    "    extraction_stats.append(\n",
    "        {\n",
    "            \"Language\": lang_config[\"name\"],\n",
    "            \"Code\": lang_code,\n",
    "            \"Documents\": len(markdown_files),\n",
    "            \"Sentences\": total_sentences,\n",
    "            \"Avg per Doc\": (\n",
    "                f\"{total_sentences / len(markdown_files):.1f}\"\n",
    "                if markdown_files\n",
    "                else \"0\"\n",
    "            ),\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4b3cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Code</th>\n",
       "      <th>Documents</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Avg per Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tamil</td>\n",
       "      <td>ta</td>\n",
       "      <td>84</td>\n",
       "      <td>9533</td>\n",
       "      <td>113.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>bn</td>\n",
       "      <td>27</td>\n",
       "      <td>6330</td>\n",
       "      <td>234.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thai</td>\n",
       "      <td>th</td>\n",
       "      <td>291</td>\n",
       "      <td>9036</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swahili</td>\n",
       "      <td>sw</td>\n",
       "      <td>310</td>\n",
       "      <td>15260</td>\n",
       "      <td>49.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estonian</td>\n",
       "      <td>et</td>\n",
       "      <td>251</td>\n",
       "      <td>15204</td>\n",
       "      <td>60.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Language Code  Documents  Sentences Avg per Doc\n",
       "0     Tamil   ta         84       9533       113.5\n",
       "1   Bengali   bn         27       6330       234.4\n",
       "2      Thai   th        291       9036        31.1\n",
       "3   Swahili   sw        310      15260        49.2\n",
       "4  Estonian   et        251      15204        60.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(extraction_stats))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
