{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2e9769",
   "metadata": {},
   "source": [
    "# Objective I: Automated Parallel Corpus Generation\n",
    "\n",
    "This notebook will create a parallel corpus for scientific translation by:\n",
    "\n",
    "1. Collecting article metadata from the [OpenAlex](https://openalex.org/) Database\n",
    "2. Automatically download the raw PDFs\n",
    "3. Convert PDFs to markdown (preserving layout)\n",
    "4. Filter by language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d46f2",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b64ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = {\n",
    "    \"ta\": {\"name\": \"Tamil\", \"max_articles\": 250},\n",
    "    \"he\": {\"name\": \"Hebrew\", \"max_articles\": 250},\n",
    "    \"lv\": {\"name\": \"Latvian\", \"max_articles\": 250},\n",
    "}\n",
    "\n",
    "# Pipeline control flags\n",
    "DOWNLOAD_METADATA = True\n",
    "DOWNLOAD_PDFS = True\n",
    "GENERATE_MARKDOWN = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e23812",
   "metadata": {},
   "source": [
    "### Imports and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffe2b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using the pymupdf_layout package for a greatly improved page layout analysis.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import pymupdf4llm\n",
    "from lingua import LanguageDetectorBuilder\n",
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from requests.adapters import HTTPAdapter, Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72bcf451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created\n",
      "Data directory: c:\\Users\\lucas\\OneDrive\\Desktop\\projects\\2025-11-17_Averroes-AI\\data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path.cwd() / \"data\"\n",
    "METADATA_DIR = DATA_DIR / \"metadata\"\n",
    "PDFS_DIR = DATA_DIR / \"pdfs\"\n",
    "EXTRACTED_DIR = DATA_DIR / \"extracted\"\n",
    "RESULTS_DIR = Path.cwd().parent / \"results\"\n",
    "\n",
    "for dir_path in [DATA_DIR, METADATA_DIR, PDFS_DIR, EXTRACTED_DIR, RESULTS_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Directories created\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e275b5b",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134e36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_abstract(inverted_index):\n",
    "    if not inverted_index:\n",
    "        return \"\"\n",
    "\n",
    "    word_indeces = []\n",
    "    for word, indeces in inverted_index.items():\n",
    "        word_indeces.extend([(idx, word) for idx in indeces])\n",
    "\n",
    "    sorted_indeces = sorted(word_indeces, key=lambda x: x[0])\n",
    "    return \" \".join([index[1] for index in sorted_indeces])\n",
    "\n",
    "\n",
    "def download_metadata(lang_code: str, max_articles: int, output_dir: Path):\n",
    "    \"\"\"Download article metadata from OpenAlex\"\"\"\n",
    "    url = \"https://api.openalex.org/works\"\n",
    "    params = {\n",
    "        \"filter\": f\"language:{lang_code},type:article\",\n",
    "        \"select\": \"abstract_inverted_index,primary_location,title,doi,publication_date\",\n",
    "        \"mailto\": \"example@email.com\",\n",
    "        \"page\": 1,\n",
    "    }\n",
    "\n",
    "    session = requests.Session()\n",
    "    article_data = []\n",
    "    total_articles = 0\n",
    "\n",
    "    with tqdm(total=max_articles, desc=f\"Collecting {lang_code} articles\") as pbar:\n",
    "        while total_articles < max_articles:\n",
    "            response = session.get(url, params=params)\n",
    "            results = response.json()[\"results\"]\n",
    "\n",
    "            for result in results:\n",
    "                primary_location = result[\"primary_location\"]\n",
    "                pdf_url = primary_location.get(\"pdf_url\", \"\")\n",
    "\n",
    "                if not pdf_url:\n",
    "                    continue\n",
    "\n",
    "                abstract = reconstruct_abstract(result[\"abstract_inverted_index\"])\n",
    "\n",
    "                article_data.append(\n",
    "                    {\n",
    "                        \"title\": result[\"title\"],\n",
    "                        \"abstract\": abstract,\n",
    "                        \"pdf_url\": pdf_url,\n",
    "                        \"doi\": result[\"doi\"],\n",
    "                        \"publication_date\": result[\"publication_date\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                pbar.update(1)\n",
    "                total_articles += 1\n",
    "                if total_articles >= max_articles:\n",
    "                    break\n",
    "\n",
    "            params[\"page\"] += 1\n",
    "            time.sleep(4)\n",
    "    df = pd.DataFrame(article_data)\n",
    "    metadata_path = output_dir / f\"{lang_code}_article_data.csv\"\n",
    "    df.to_csv(metadata_path, index=False, encoding=\"utf-8\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def setup_pdf_driver(download_dir: Path):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\n",
    "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "    )\n",
    "    options.add_experimental_option(\n",
    "        \"prefs\",\n",
    "        {\n",
    "            \"download.default_directory\": str(download_dir.absolute()),\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"plugins.always_open_pdf_externally\": True,\n",
    "            \"plugins.plugins_disabled\": [\"Chrome PDF Viewer\"],\n",
    "        },\n",
    "    )\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "def download_pdf(driver, pdf_url: str):\n",
    "    driver.get(pdf_url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "    )\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "def detect_language(text: str, detector):\n",
    "    result = detector.detect_language_of(text)\n",
    "    return result.iso_code_639_1.name.lower() if result else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b4cecf",
   "metadata": {},
   "source": [
    "### Download Metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bda402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Step 1: Downloading Metadata from OpenAlex"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Tamil (ta)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e52ecbb900b4f4cb089409e32d52640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting ta articles:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLIC 2008 Parameters</td>\n",
       "      <td>This note presents the CLIC parameter set as o...</td>\n",
       "      <td>http://cds.cern.ch/record/1132079</td>\n",
       "      <td>None</td>\n",
       "      <td>2008-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extra-axial Ependymoma —Case Report—</td>\n",
       "      <td>A 13-year-old boy presented with a very unusua...</td>\n",
       "      <td>https://www.jstage.jst.go.jp/article/nmc1959/3...</td>\n",
       "      <td>https://doi.org/10.2176/nmc.34.295</td>\n",
       "      <td>1994-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0                  CLIC 2008 Parameters   \n",
       "1  Extra-axial Ependymoma —Case Report—   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  This note presents the CLIC parameter set as o...   \n",
       "1  A 13-year-old boy presented with a very unusua...   \n",
       "\n",
       "                                             pdf_url  \\\n",
       "0                  http://cds.cern.ch/record/1132079   \n",
       "1  https://www.jstage.jst.go.jp/article/nmc1959/3...   \n",
       "\n",
       "                                  doi publication_date  \n",
       "0                                None       2008-10-01  \n",
       "1  https://doi.org/10.2176/nmc.34.295       1994-01-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Hebrew (he)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e5dae8045f4a70a64d041d9be0ef89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting he articles:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;i&gt;ATHENA&lt;/i&gt;,&lt;i&gt;ARTEMIS&lt;/i&gt;,&lt;i&gt;HEPHAESTUS&lt;/i&gt;...</td>\n",
       "      <td>A software package for the analysis of X-ray a...</td>\n",
       "      <td>http://journals.iucr.org/s/issues/2005/04/00/p...</td>\n",
       "      <td>https://doi.org/10.1107/s0909049505012719</td>\n",
       "      <td>2005-06-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE&lt;i&gt;NUCLEAR SPECTROSCOPIC TELESCOPE ARRAY&lt;/i...</td>\n",
       "      <td>The Nuclear Spectroscopic Telescope Array (NuS...</td>\n",
       "      <td>https://iopscience.iop.org/article/10.1088/000...</td>\n",
       "      <td>https://doi.org/10.1088/0004-637x/770/2/103</td>\n",
       "      <td>2013-05-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  <i>ATHENA</i>,<i>ARTEMIS</i>,<i>HEPHAESTUS</i>...   \n",
       "1  THE<i>NUCLEAR SPECTROSCOPIC TELESCOPE ARRAY</i...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  A software package for the analysis of X-ray a...   \n",
       "1  The Nuclear Spectroscopic Telescope Array (NuS...   \n",
       "\n",
       "                                             pdf_url  \\\n",
       "0  http://journals.iucr.org/s/issues/2005/04/00/p...   \n",
       "1  https://iopscience.iop.org/article/10.1088/000...   \n",
       "\n",
       "                                           doi publication_date  \n",
       "0    https://doi.org/10.1107/s0909049505012719       2005-06-15  \n",
       "1  https://doi.org/10.1088/0004-637x/770/2/103       2013-05-30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Latvian (lv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1afa1cb2f8493fb0f612bfd020fb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting lv articles:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>doi</th>\n",
       "      <th>publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elliptic curve cryptosystems</td>\n",
       "      <td>We discuss analogs based on elliptic curves ov...</td>\n",
       "      <td>https://www.ams.org/mcom/1987-48-177/S0025-571...</td>\n",
       "      <td>https://doi.org/10.1090/s0025-5718-1987-0866109-5</td>\n",
       "      <td>1987-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theory of the Role of Covalence in the Perovsk...</td>\n",
       "      <td>The theory of semicovalent exchange is reviewe...</td>\n",
       "      <td>http://link.aps.org/pdf/10.1103/PhysRev.100.564</td>\n",
       "      <td>https://doi.org/10.1103/physrev.100.564</td>\n",
       "      <td>1955-10-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                       Elliptic curve cryptosystems   \n",
       "1  Theory of the Role of Covalence in the Perovsk...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  We discuss analogs based on elliptic curves ov...   \n",
       "1  The theory of semicovalent exchange is reviewe...   \n",
       "\n",
       "                                             pdf_url  \\\n",
       "0  https://www.ams.org/mcom/1987-48-177/S0025-571...   \n",
       "1    http://link.aps.org/pdf/10.1103/PhysRev.100.564   \n",
       "\n",
       "                                                 doi publication_date  \n",
       "0  https://doi.org/10.1090/s0025-5718-1987-0866109-5       1987-01-01  \n",
       "1            https://doi.org/10.1103/physrev.100.564       1955-10-15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Code</th>\n",
       "      <th>Articles</th>\n",
       "      <th>With Abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tamil</td>\n",
       "      <td>ta</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>he</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>lv</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language Code  Articles  With Abstracts\n",
       "0    Tamil   ta       250             250\n",
       "1   Hebrew   he       250             250\n",
       "2  Latvian   lv       250             250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if DOWNLOAD_METADATA:\n",
    "    display(Markdown(\"#### Step 1: Downloading Metadata from OpenAlex\"))\n",
    "    metadata_stats = []\n",
    "\n",
    "    for lang_code, config in LANGUAGES.items():\n",
    "        display(Markdown(f\"##### {config['name']} ({lang_code})\"))\n",
    "\n",
    "        df = download_metadata(lang_code, config[\"max_articles\"], METADATA_DIR)\n",
    "\n",
    "        metadata_stats.append(\n",
    "            {\n",
    "                \"Language\": config[\"name\"],\n",
    "                \"Code\": lang_code,\n",
    "                \"Articles\": len(df),\n",
    "                \"With Abstracts\": df[\"abstract\"].notna().sum(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        display(df.head(2))\n",
    "    # Summary\n",
    "    summary_df = pd.DataFrame(metadata_stats)\n",
    "    display(Markdown(\"##### Summary\"))\n",
    "    display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5cc612",
   "metadata": {},
   "source": [
    "### Download PDFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c190ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Step 2: Downloading Article PDFs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Tamil (ta)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66655967347947b0a7c22e25fb662cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 250/250 PDFs\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Hebrew (he)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458fde0d4ffd48b6be55363b4a15d1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 250/250 PDFs\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Latvian (lv)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1cff435252439389a429d24388b366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 250/250 PDFs\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "##### Download Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Attempted</th>\n",
       "      <th>Downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tamil</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hebrew</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latvian</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language  Attempted  Downloaded\n",
       "0    Tamil        250         250\n",
       "1   Hebrew        250         250\n",
       "2  Latvian        250         250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if DOWNLOAD_PDFS:\n",
    "    display(Markdown(\"#### Step 2: Downloading Article PDFs\"))\n",
    "\n",
    "    download_stats = []\n",
    "\n",
    "    for lang_code, config in LANGUAGES.items():\n",
    "        display(Markdown(f\"##### {config['name']} ({lang_code})\"))\n",
    "\n",
    "        lang_pdf_dir = PDFS_DIR / lang_code\n",
    "        lang_pdf_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Load metadata\n",
    "        metadata_path = METADATA_DIR / f\"{lang_code}_article_data.csv\"\n",
    "        if not metadata_path.exists():\n",
    "            print(\"No metadata found, skipping\")\n",
    "            continue\n",
    "\n",
    "        articles_df = pd.read_csv(metadata_path)\n",
    "        driver = setup_pdf_driver(lang_pdf_dir)\n",
    "\n",
    "        # Download\n",
    "        success_count = 0\n",
    "        for idx, article in tqdm(\n",
    "            articles_df.iterrows(), total=len(articles_df), desc=\"Downloading\"\n",
    "        ):\n",
    "            try:\n",
    "                download_pdf(driver, article[\"pdf_url\"])\n",
    "                success_count += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        download_stats.append(\n",
    "            {\n",
    "                \"Language\": config[\"name\"],\n",
    "                \"Attempted\": len(articles_df),\n",
    "                \"Downloaded\": success_count,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Downloaded {success_count}/{len(articles_df)} PDFs\")\n",
    "\n",
    "    # Summary\n",
    "    display(Markdown(\"##### Download Summary\"))\n",
    "    display(pd.DataFrame(download_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcee48c",
   "metadata": {},
   "source": [
    "### Convert to Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c06674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Step 3: Converting PDFs to Markdown"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Tamil (ta)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b4e5aad4a1403f8db00bcc7047ff9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing ta:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\Users\\\\lucas\\\\OneDrive\\\\Desktop\\\\projects\\\\2025-11-17_Averroes-AI\\\\data\\\\pdfs\\\\ta\\\\E664fbzz7W84SWTKM.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mpdf_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     wrong_lang_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\pathlib.py:1147\u001b[39m, in \u001b[36mPath.unlink\u001b[39m\u001b[34m(self, missing_ok)\u001b[39m\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     os.unlink(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\Users\\\\lucas\\\\OneDrive\\\\Desktop\\\\projects\\\\2025-11-17_Averroes-AI\\\\data\\\\pdfs\\\\ta\\\\E664fbzz7W84SWTKM.pdf'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m             wrong_lang_count += \u001b[32m1\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         \u001b[43mpdf_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmissing_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m         error_count += \u001b[32m1\u001b[39m\n\u001b[32m     45\u001b[39m processing_stats.append(\n\u001b[32m     46\u001b[39m     {\n\u001b[32m     47\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLanguage\u001b[39m\u001b[33m\"\u001b[39m: config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m     }\n\u001b[32m     56\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Python\\pythoncore-3.11-64\\Lib\\pathlib.py:1147\u001b[39m, in \u001b[36mPath.unlink\u001b[39m\u001b[34m(self, missing_ok)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1143\u001b[39m \u001b[33;03mRemove this file or link.\u001b[39;00m\n\u001b[32m   1144\u001b[39m \u001b[33;03mIf the path is a directory, use rmdir() instead.\u001b[39;00m\n\u001b[32m   1145\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     os.unlink(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1149\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_ok:\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\Users\\\\lucas\\\\OneDrive\\\\Desktop\\\\projects\\\\2025-11-17_Averroes-AI\\\\data\\\\pdfs\\\\ta\\\\E664fbzz7W84SWTKM.pdf'"
     ]
    }
   ],
   "source": [
    "if GENERATE_MARKDOWN:\n",
    "    display(Markdown(\"#### Step 3: Converting PDFs to Markdown\"))\n",
    "\n",
    "    detector = LanguageDetectorBuilder.from_all_languages().build()\n",
    "    processing_stats = []\n",
    "\n",
    "    for lang_code, config in LANGUAGES.items():\n",
    "        display(Markdown(f\"##### {config['name']} ({lang_code})\"))\n",
    "\n",
    "        lang_pdf_dir = PDFS_DIR / lang_code\n",
    "        lang_extracted_dir = EXTRACTED_DIR / lang_code\n",
    "        lang_extracted_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if not lang_pdf_dir.exists():\n",
    "            print(f\"No PDFs found, skipping\")\n",
    "            continue\n",
    "\n",
    "        pdf_files = list(lang_pdf_dir.glob(\"*.pdf\"))\n",
    "        kept_count = 0\n",
    "        wrong_lang_count = 0\n",
    "        error_count = 0\n",
    "\n",
    "        for pdf_path in tqdm(\n",
    "            pdf_files, total=len(pdf_files), desc=f\"Processing {lang_code}\"\n",
    "        ):\n",
    "            try:\n",
    "                md_text = pymupdf4llm.to_markdown(str(pdf_path))\n",
    "\n",
    "                detected_code = detect_language(md_text, detector)\n",
    "                if detected_code == lang_code:\n",
    "                    new_pdf_path = lang_pdf_dir / f\"{kept_count}.pdf\"\n",
    "                    pdf_path.rename(new_pdf_path)\n",
    "\n",
    "                    md_path = lang_extracted_dir / f\"{kept_count}.md\"\n",
    "                    md_path.write_text(md_text, encoding=\"utf-8\")\n",
    "                    kept_count += 1\n",
    "                else:\n",
    "                    pdf_path.unlink()\n",
    "                    wrong_lang_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                pdf_path.unlink(missing_ok=True)\n",
    "                error_count += 1\n",
    "\n",
    "        processing_stats.append(\n",
    "            {\n",
    "                \"Language\": config[\"name\"],\n",
    "                \"Total PDFs\": len(pdf_files),\n",
    "                \"Kept\": kept_count,\n",
    "                \"Wrong Language\": wrong_lang_count,\n",
    "                \"Errors\": error_count,\n",
    "                \"Success Rate\": (\n",
    "                    f\"{kept_count/len(pdf_files)*100:.1f}%\" if pdf_files else \"0%\"\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(f\"Kept {kept_count}/{len(pdf_files)} documents\")\n",
    "\n",
    "    # Summary\n",
    "    display(Markdown(\"### Processing Summary\"))\n",
    "    stats_df = pd.DataFrame(processing_stats)\n",
    "    display(stats_df)\n",
    "\n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    stats_df.plot(\n",
    "        x=\"Language\", y=[\"Kept\", \"Wrong Language\", \"Errors\"], kind=\"bar\", ax=ax\n",
    "    )\n",
    "    ax.set_title(\"PDF Processing Results by Language\")\n",
    "    ax.set_ylabel(\"Number of Documents\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / \"processing_results.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f891167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
